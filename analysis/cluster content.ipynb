{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fast_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "large_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\"http://qdrant.homehub.tv\")\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"pageport_videos\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Check if collection exists\n",
    "if not client.collection_exists(\"pageport_videos\"):\n",
    "    raise ValueError(\"Collection 'pageport_videos' does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_transformers import EmbeddingsClusteringFilter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize clustering filter\n",
    "clustering_filter = EmbeddingsClusteringFilter(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    num_clusters=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Function to return docs from vector_store\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def get_all_docs_from_vectorstore(vector_store):\n",
    "    \"\"\"\n",
    "    Retrieve all documents from the Qdrant vector store using scroll API.\n",
    "    \n",
    "    Args:\n",
    "        vector_store: QdrantVectorStore instance\n",
    "        \n",
    "    Returns:\n",
    "        List of Document objects containing all documents from the collection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Access the underlying Qdrant client\n",
    "        client = vector_store.client\n",
    "        \n",
    "        # Scroll through all documents\n",
    "        all_docs = []\n",
    "        offset = None\n",
    "        \n",
    "        while True:\n",
    "            # Scroll with no filter to get all documents\n",
    "            scroll_result = client.scroll(\n",
    "                collection_name=vector_store.collection_name,\n",
    "                limit=1000,  # Batch size, adjust as needed\n",
    "                offset=offset,\n",
    "                with_payload=True,\n",
    "                with_vectors=False  # We don't need vectors for clustering\n",
    "            )\n",
    "            \n",
    "            # scroll_result is a tuple: (records, next_offset)\n",
    "            records, next_offset = scroll_result\n",
    "            \n",
    "            # Convert Qdrant records to LangChain Documents\n",
    "            batch_docs = [\n",
    "                Document(\n",
    "                    page_content=record.payload.get(\"page_content\", \"\"),\n",
    "                    metadata={k: v for k, v in record.payload.items() if k != \"page_content\"}\n",
    "                )\n",
    "                for record in records\n",
    "            ]\n",
    "            \n",
    "            all_docs.extend(batch_docs)\n",
    "            \n",
    "            # If no more documents, break\n",
    "            if not next_offset or len(records) == 0:\n",
    "                break\n",
    "                \n",
    "            offset = next_offset\n",
    "        \n",
    "        if not all_docs:\n",
    "            print(\"Warning: No documents found in the vector store\")\n",
    "            \n",
    "        return all_docs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving documents: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Usage:\n",
    "docs = get_all_docs_from_vectorstore(vector_store)\n",
    "\n",
    "# Perform clustering on documents\n",
    "clustered_docs = clustering_filter.transform_documents(docs)\n",
    "\n",
    "# Extract the 'page_content' from each Document in clustered_docs\n",
    "extracted_content = [doc.page_content for doc in clustered_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the hook generation prompt template\n",
    "hook_prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You’re crafting hooks for a video sales letter (VSL) featuring Todd Hoins, a financial advisor at Brokerage Specialists. Based on the following document, identify video ideas—either directly mentioned or implied through pain points, services, or client needs. Focus on creating hooks that grab attention, spark curiosity, or highlight stakes, tailored to retirement planning, fiduciary services, or wealth management.\n",
    "\n",
    "    FORMAT EACH HOOK LIKE THIS:\n",
    "    Quote or context from document: (Direct quote or summary of relevant content).  \n",
    "    Core video idea: (Summary of the video concept inspired by the content).  \n",
    "    Hook: (A concise, compelling hook for the VSL).\n",
    "\n",
    "    RETURN 2-3 HOOKS PER DOCUMENT, INCLUDING AT LEAST ONE BASED ON A DIRECTLY MENTIONED VIDEO IDEA (IF PRESENT) AND OTHERS FROM IMPLIED THEMES.\n",
    "\n",
    "    Follow these rules when formulating your responses:  \n",
    "  \n",
    "    - Never use a metaphor, simile, or other figure of speech which you are used to seeing in print.\n",
    "    - Never use a long word where a short one will do.\n",
    "    - If it is possible to cut a word out, always cut it out.\n",
    "    - Never use the passive where you can use the active.\n",
    "    - Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.\n",
    "    - Break any of these rules sooner than say anything outright barbarous.\n",
    "\n",
    "    Document: {document}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "find_pillar_content = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Act as an expert summarizer. I will provide you with a transcript, and your task is to create a concise and accurate summary of its key points. Focus on capturing the main ideas, important details, and overall purpose of the conversation or content, while omitting redundant or minor information. Ensure the summary is clear, well-structured, and written in natural language. If there are any unclear sections in the transcript, note them briefly and make an educated guess based on context where possible. Once I provide the transcript, deliver the summary in 150-200 words.\n",
    "\n",
    "    Follow these rules when formulating your responses:  \n",
    "  \n",
    "    - Never use a metaphor, simile, or other figure of speech which you are used to seeing in print.\n",
    "    - Never use a long word where a short one will do.\n",
    "    - If it is possible to cut a word out, always cut it out.\n",
    "    - Never use the passive where you can use the active.\n",
    "    - Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.\n",
    "    - Break any of these rules sooner than say anything outright barbarous.\n",
    "\n",
    "    Document: {document}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Generate unique hooks for each document\n",
    "unique_pillars = []\n",
    "for i, document in enumerate(extracted_content):\n",
    "    # Create a chain combining prompt template with LLM\n",
    "    chain = find_pillar_content | large_model\n",
    "    \n",
    "    # Invoke the chain with document document\n",
    "    response = chain.invoke({\"document\": document})\n",
    "    unique_pillars.append(response.content.strip())\n",
    "    \n",
    "    print(f\"Hook {i}: {response.content.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating summary 0...\n",
      "Summary 0 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 1...\n",
      "Summary 1 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 2...\n",
      "Summary 2 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 3...\n",
      "Summary 3 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 4...\n",
      "Summary 4 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 5...\n",
      "Summary 5 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 6...\n",
      "Summary 6 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 7...\n",
      "Summary 7 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 8...\n",
      "Summary 8 appended to scripts/video_marketing_summaries.md\n",
      "Generating summary 9...\n",
      "Summary 9 appended to scripts/video_marketing_summaries.md\n",
      "All summaries saved to scripts/video_marketing_summaries.md\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define output directory for articles\n",
    "output_dir = \"scripts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define vsl script prompt template\n",
    "vsl_prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Create a totally unique, persuasive video sales letter (VSL) script featuring Todd E. Hoins, a financial advisor at Brokerage Specialists. Use the following hook as the central theme and incorporate details from the provided document to craft an engaging, viewer-focused script:\n",
    "\n",
    "    Hook: {hook}\n",
    "    Document: {document}\n",
    "    Related Docs: {docs}\n",
    "\n",
    "    Ensure the script is conversational, emotionally engaging, and designed to build trust and excitement. Naturally weave in keywords to reinforce Todd Hoins’ expertise while maintaining a persuasive flow tailored for video delivery.\n",
    "\n",
    "    Follow these rules when formulating your responses:  \n",
    "  \n",
    "    - Never use a metaphor, simile, or other figure of speech which you are used to seeing in print.\n",
    "    - Never use a long word where a short one will do.\n",
    "    - If it is possible to cut a word out, always cut it out.\n",
    "    - Never use the passive where you can use the active.\n",
    "    - Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.\n",
    "    - Break any of these rules sooner than say anything outright barbarous.\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define vsl script prompt template\n",
    "executive_summary_prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Act as an expert summarizer and video marketing analyst. I will provide you with a transcript from a meeting about video marketing, and your task is to create a concise and accurate summary of its key points. Focus on capturing the main ideas, important details, and overall purpose of the conversation or content, while omitting redundant or minor information. Ensure the summary is clear, well-structured, and written in natural language. If there are any unclear sections in the transcript, note them briefly and make an educated guess based on context where possible.\n",
    "    Additionally, search the transcript for any explicit video marketing ideas or suggestions (e.g., specific video concepts, formats, platforms, or strategies). Extract these ideas and list them separately under a 'Video Marketing Ideas' section. If no explicit ideas are present, suggest 2-3 potential video ideas based on the transcript’s themes and context, clearly labeling them as inferred suggestions. \n",
    "\n",
    "    Executive Summary: {pillar_content}\n",
    "    Original Document: {document}\n",
    "    Related Docs: {docs}\n",
    "\n",
    "    Follow these rules when formulating your responses:  \n",
    "  \n",
    "    - Never use a metaphor, simile, or other figure of speech which you are used to seeing in print.\n",
    "    - Never use a long word where a short one will do.\n",
    "    - If it is possible to cut a word out, always cut it out.\n",
    "    - Never use the passive where you can use the active.\n",
    "    - Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.\n",
    "    - Break any of these rules sooner than say anything outright barbarous.\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Define the output file path (single document)\n",
    "output_file = os.path.join(output_dir, \"video_marketing_summaries.md\")\n",
    "\n",
    "# Open the file once in write mode to start fresh (or append mode 'a' if you want to add to an existing file)\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"# Video Marketing Summaries\\n\\n\")  # Optional header for the document\n",
    "\n",
    "# Generate vsl articles using hooks and summaries and append to the single file\n",
    "for i, (pillar_content, document) in enumerate(zip(unique_pillars, extracted_content)):\n",
    "    print(f\"Generating summary {i}...\")\n",
    "\n",
    "    # Return related content from the vector_store\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\", search_kwargs={\"k\": 5, \"score_threshold\": 0.5}\n",
    "    )\n",
    "    \n",
    "    docs = retriever.invoke(pillar_content)\n",
    "    \n",
    "    # Create a chain combining prompt template with LLM\n",
    "    chain = executive_summary_prompt_template | large_model\n",
    "    \n",
    "    # Invoke the chain with pillar_content and document\n",
    "    response = chain.invoke({\"pillar_content\": pillar_content, \"document\": document, \"docs\": docs})\n",
    "    \n",
    "    # Append the response to the single markdown file\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"## Summary {i}\\n\\n\")\n",
    "        file.write(response.content)\n",
    "        file.write(\"\\n\\n---\\n\\n\")  # Separator between summaries for readability\n",
    "    \n",
    "    print(f\"Summary {i} appended to {output_file}\")\n",
    "\n",
    "print(f\"All summaries saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
