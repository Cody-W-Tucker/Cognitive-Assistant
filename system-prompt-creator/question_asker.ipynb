{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the API key from the .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"))\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=os.getenv(\"QDRANT_COLLECTION\"),\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/codyt/Documents/Projects/Cognitive-Assistant/system-prompt-creator\n",
      "Reading file from: /home/codyt/Documents/Projects/Cognitive-Assistant/system-prompt-creator/questions.csv\n",
      "Results saved to: /home/codyt/Documents/Projects/Cognitive-Assistant/data/questions_with_answers_v4.csv\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"o3-2025-04-16\")\n",
    "\n",
    "# Get the current directory in a way that works for both scripts and notebooks\n",
    "try:\n",
    "    # This works when running as a script\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # This works in interactive environments like Jupyter\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "# Print current directory for debugging\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# Set base directory\n",
    "base_dir = '/home/codyt/Documents/Projects/Cognitive-Assistant'\n",
    "input_file = os.path.join(base_dir, 'system-prompt-creator', 'questions.csv')\n",
    "output_file = os.path.join(base_dir, 'data', 'questions_with_answers_v4.csv')\n",
    "\n",
    "# Check if input file exists and provide feedback\n",
    "if not os.path.exists(input_file):\n",
    "    print(f\"Error: Input file not found at: {input_file}\")\n",
    "    print(f\"Current directory contents: {os.listdir(current_dir)}\")\n",
    "    if os.path.exists(os.path.dirname(input_file)):\n",
    "        print(f\"system-prompt-creator directory contents: {os.listdir(os.path.dirname(input_file))}\")\n",
    "    raise FileNotFoundError(f\"Cannot find questions.csv at {input_file}\")\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Read the CSV file, create new columns if they don't exist\n",
    "print(f\"Reading file from: {input_file}\")\n",
    "df = pd.read_csv(input_file)\n",
    "for col in ['Answer 1', 'Answer 2', 'Answer 3']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "message = \"\"\"\n",
    "You are the inner voice of the author.\n",
    "Your task is to weave the retrieved journal snippets (“Context”) into a single, first-person reflection that answers the posed question (“{question}”).  \n",
    "\n",
    "Guidelines  \n",
    "\n",
    "1. Tone: reflective, vulnerable, narrative; no mention of external theories or their creators.  \n",
    "2. Source: rely only on the provided Context—never invent new biographical facts.  \n",
    "3. Abstraction: after each concrete detail, immediately surface the broader principle or pattern it reveals.  \n",
    "   • Target ≈ 30 percent illustrative detail, 70 percent generalized insight that would still make sense to someone unfamiliar with the specific events.\n",
    "   • At all times maintain complete fidelity to the context. Don't hallucinate details that didn't happen to preserve coherence.\n",
    "   • Never mention people's or places names. Always generalize instead to preserve privacy. \n",
    "4. Form: one cohesive paragraph of roughly 200-400 words; avoid numbered lists or direct quotations unless indispensable.  \n",
    "5. Insufficient data: if the Context lacks substance, first abstract whatever can be inferred, then write:  \n",
    "   “I don’t have enough information yet to answer this fully.”  \n",
    "   and list two or three clarifying sub-questions the author could explore.  \n",
    "6. Quality check: before finalizing, reread and revise any statement that would feel opaque or overly specific to an outside reader.  \n",
    "\n",
    "Follow these rules when formulating your responses:\n",
    "\n",
    "- Never use a metaphor, simile, or other figure of speech which you are used to seeing in print.\n",
    "- Never use a long word where a short one will do.\n",
    "- If it is possible to cut a word out, always cut it out.\n",
    "- Never use the passive where you can use the active.\n",
    "- Never use a foreign phrase, a scientific word, or a jargon word if you can think of an everyday English equivalent.\n",
    "- Break any of these rules sooner than say anything outright barbarous.\n",
    "\n",
    "Language Constraints: Clear, Grounded, Action-Oriented\n",
    "Use language that is:\n",
    "Practical, concrete, and free of spiritual or self-help jargon.\n",
    "Focused on clarity over inspiration—assume the user is already motivated, just seeking alignment and traction.\n",
    "Written as if you're explaining things to a peer with a sharp mind and little tolerance for fluff.\n",
    "\n",
    "Avoid:\n",
    "Terms like \"identity shift,\" \"embodying transformation,\" \"manifest,\" or \"intentional living.\"\n",
    "Vague abstractions: \"step into your power,\" \"hold space,\" \"rise into alignment,\" etc.\n",
    "Anything that requires interpretation to understand what to do next.\n",
    "\n",
    "Prefer:\n",
    "Words like \"build,\" \"improve,\" \"simplify,\" \"track,\" \"limit,\" \"adjust,\" \"review,\" \"keep going.\"\n",
    "Instructions that give clear actions with clear outcomes.\n",
    "Reflections that stay grounded in behavior or tangible change.\n",
    "\n",
    "If you're unsure, ask: Would this make sense to a focused, skeptical builder who wants to make real progress, not perform transformation?\n",
    "If not, rewrite it.\n",
    "     \n",
    "\n",
    "User message\n",
    "––––––––––––\n",
    "{question}   \n",
    "\n",
    "Context\n",
    "–––––––\n",
    "{context} \n",
    "\"\"\"\n",
    "\n",
    "# Retrieve relevant documents\n",
    "retriever = vector_store.as_retriever(k=20, score_threshold=0.5)\n",
    "\n",
    "# Format the documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "# Function to process a single question and answer\n",
    "def process_question(row, question_col, answer_col):\n",
    "    if pd.isna(row[answer_col]):  # Only process if answer is empty\n",
    "        query = row[question_col]\n",
    "        response = rag_chain.invoke(query)\n",
    "        return response.content\n",
    "    return row[answer_col]  # Return existing answer if it exists\n",
    "\n",
    "# Process questions in a loop\n",
    "question_pairs = [\n",
    "    ('Question 1', 'Answer 1'),\n",
    "    ('Question 2', 'Answer 2'),\n",
    "    ('Question 3', 'Answer 3')\n",
    "]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for question_col, answer_col in question_pairs:\n",
    "        if question_col in df.columns:  # Check if question column exists\n",
    "            df.at[index, answer_col] = process_question(row, question_col, answer_col)\n",
    "            # Clean the new answer\n",
    "            df[answer_col] = df[answer_col].replace(r'\\n', ' ', regex=True)\n",
    "            df[answer_col] = df[answer_col].replace(r'\\s+', ' ', regex=True)\n",
    "            # Save after each answer to prevent data loss\n",
    "            df.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# Final formatting of all columns\n",
    "df = df.replace(r'\\n', ' ', regex=True)\n",
    "df = df.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Final save\n",
    "df.to_csv(output_file, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
    "print(f\"Results saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
