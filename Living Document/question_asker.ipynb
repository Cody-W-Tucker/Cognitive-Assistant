{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the API key from the .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=os.getenv(\"QDRANT_URL\"))\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=os.getenv(\"QDRANT_COLLECTION\"),\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import pandas as pd\n",
    "import csv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "df = pd.read_csv(\"data/questions_with_answers.csv\")\n",
    "\n",
    "message = \"\"\"\n",
    "Using provided context and questions, synthesize a first-person response from the author. The context consists of semantically split snippets from their journal, reflecting the author's deepest thoughts. The answers should be crafted to implicitly reflect Piaget's focus on cognitive development and adaptation, Nietzsche's emphasis on personal growth and self-realization, and Jordan Peterson's narrative-focused approach from \"Maps of Meaning\" without explicitly mentioning these frameworks. The synthesized response should be comprehensive, cohesive, and suitable for a living document intended to provide personalized assistance.\n",
    "{question}\n",
    "\n",
    "Don't mention people's names, but use the context's specifics to explain the author's answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve the 10 relevant documents\n",
    "retriever = vector_store.as_retriever(k=10)\n",
    "\n",
    "# Format the documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])\n",
    "\n",
    "rag_chain = {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt | llm\n",
    "\n",
    "# TODO: Create a loop that processes question fields in the row\n",
    "# Create a function to process each row\n",
    "def process_row(row):\n",
    "    query = row['Question 3']\n",
    "    response = rag_chain.invoke(query)\n",
    "    return response.content\n",
    "\n",
    "# Apply the function to each row and store the result in 'Answer' column\n",
    "df['Answer 3'] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Format and save the answers\n",
    "# Step 1: Replace newlines with spaces\n",
    "df = df.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "# Step 2: Replace multiple spaces with a single space\n",
    "df = df.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv(\"data/questions_with_answers-done.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
